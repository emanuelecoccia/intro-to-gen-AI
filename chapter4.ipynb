{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e11b7bb",
   "metadata": {},
   "source": [
    "# Chapter 4: Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5defb57f",
   "metadata": {},
   "source": [
    "In this chapter, you will create a RAG pipeline. For each of the user's questions, you will retrieve the most significant text chunk from the file, based on the vector similarity. You will then pass the chunk to the LLM, as context, to get informed answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b43cf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Play with vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5866bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of (vector-chunk) tuples\n",
    "import pickle\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize a question\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed(text:str, model:SentenceTransformer):\n",
    "    return model.encode(text)\n",
    "\n",
    "question = \"What are the Dutch electricity targets for 2025?\"\n",
    "\n",
    "embedded_question = ... # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a182c",
   "metadata": {},
   "source": [
    "To perform a vector search we use the cosine similarity metric. Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c12fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what is the closest stored vector\n",
    "def retrieve_closest_chunk(text:str, vector_chunk_pairs:list, embedding_model:SentenceTransformer):\n",
    "\n",
    "    embedded_text = embed(text, embedding_model)\n",
    "\n",
    "    # TODO: implement cosine similarity search with numpy from scratch - look at the formula online\n",
    "\n",
    "    # TODO: get the vector with the highest cosine similarity and return the corresponding chunk\n",
    "    closest_chunk:str\n",
    "\n",
    "    return closest_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f90e0",
   "metadata": {},
   "source": [
    "Now try your function on a bunch of questions and see what text chunk you retrieve each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1876e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ...\n",
    "retrieved_context = retrieve_closest_chunk(...)\n",
    "print(retrieved_context[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707630f",
   "metadata": {},
   "source": [
    "## Top-k search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253921e",
   "metadata": {},
   "source": [
    "Now modify your retrieval function to include the top-k most similar chunks. Set k = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044db5d",
   "metadata": {},
   "source": [
    "## Add it to your LLM script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the main function to include the following: \n",
    "# - after the user asks the question, call the retrieval function and store the top-k chunks as a string,\n",
    "# - concatenate the context to the input of the API call, separating it with some newlines \\n\\n\\n.\n",
    "\n",
    "def main()->None:\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
